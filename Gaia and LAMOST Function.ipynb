{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cfd6ecf-07f4-428d-bdca-4abc788f2d38",
   "metadata": {},
   "source": [
    "## __Pick up Gaia EDR3 Data__ ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6378763f-4375-4f47-8ea9-67b86f6bd7c7",
   "metadata": {},
   "source": [
    "__You can obtain the required files from the following website：__\n",
    "https://warwick.ac.uk/fac/sci/physics/research/astro/research/catalogues/gaiaedr3_wd_main.fits.gz  \n",
    " (from article,  $\\textit{A catalogue of white dwarfs in Gaia EDR3}$  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f53a473-4baf-456e-9c12-48824ab1cb07",
   "metadata": {},
   "source": [
    "* __the following codes are to create a substitutable, simplified *.csv__  \n",
    "( the simplified file is in a 'temp' folder in the same folder as your file, gaiaedr3_wd_main.fits.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e8c2344-d055-4f15-9f09-d1c3ca8ac375",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# the needed module import\n",
    "# used to read the fits\n",
    "from astropy.io import fits \n",
    "\n",
    "# used to desgin functions to simplify the code\n",
    "from tqdm import tqdm, trange # not necessary, just a visible progress bar\n",
    "\n",
    "# to create a new csv\n",
    "import csv\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ecfeda55-d400-4bf7-9385-fe1e768f225d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = 'C:/Users/Administrator/Desktop/大创/Data' #the path you saved the gaiaedr3_wd_main.fits.gz\n",
    "name_list = ['WDJ_name','ra','dec','Pwd','phot_g_mean_mag_corrected']\n",
    "Pwd_limitation = 0.75 #the minimum of Pwd\n",
    "mag_limitation = [None, None]#the range of mag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ec146231-ef68-4cd4-97a0-6608197eb8ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class InputError(Exception):\n",
    "    pass\n",
    "def Gaia_EDR3_Data_Split(path,\n",
    "                        name_list,\n",
    "                        Pwd_limitation,\n",
    "                        mag_limitation,\n",
    "                        next_folder = 'Gaia',\n",
    "                        file_create = True,\n",
    "                        return_data = False):\n",
    "    \n",
    "    #through Pwd and phot_g_mean_mag_corrected\n",
    "    if 0 > Pwd_limitation or Pwd_limitation >= 1:\n",
    "        raise InputError ('Pwd_limitation should be in [0, 1)')\n",
    "    if len(mag_limitation) != 2:\n",
    "        raise InputError ('mag_limitation should be a list with 2 element or NoneType')\n",
    "    \n",
    "    if 'WDJ_name' not in name_list:\n",
    "        name_list.insert(0 , 'WDJ_name')\n",
    "    elif name_list[0] != 'WDJ_name':\n",
    "        temp = name_list[0]\n",
    "        name_list[0] = 'WDJ_name'\n",
    "        for i in range(1, len(name_list)):\n",
    "            if name_list[i] == 'WDJ_name':\n",
    "                name_list[i] = temp\n",
    "                temp = None\n",
    "                break\n",
    "    if path[len(path) - 1] == '/':\n",
    "        path = path + 'gaiaedr3_wd_main.fits.gz'\n",
    "    elif Path(path).parts[len(Path(path).parts)-1] != 'gaiaedr3_wd_main.fits.gz':\n",
    "        path = path + '/' + 'gaiaedr3_wd_main.fits.gz'\n",
    "        \n",
    "    try:\n",
    "        fits_file = fits.open(path)\n",
    "    except FileNotFoundError:\n",
    "        print('Wrong path of gaiaedr3_wd_main.fits.gz')\n",
    "    else:\n",
    "        fits_file_num = fits_file[1].header['NAXIS2']   # the total number of WDs in GaiaEDR3_WD_main.fits\n",
    "        fits_file_data = fits_file[1].data   # pre-load the data\n",
    "        fits_file.close()\n",
    "        \n",
    "        Pwd = fits_file_data.field('Pwd')\n",
    "        Mag = fits_file_data.field('phot_g_mean_mag_corrected')\n",
    "        \n",
    "        data = []\n",
    "        for j in trange(0 , fits_file_num):\n",
    "            if Pwd[j] > Pwd_limitation:\n",
    "                if mag_limitation[0] is not None and mag_limitation[1] is not None:\n",
    "                    if mag_limitation[0] < Mag[j] <= mag_limitation[1]:\n",
    "                        temp = []\n",
    "                        for i in range(len(name_list)):\n",
    "                            temp.append(fits_file_data.field(name_list[i])[j])\n",
    "                        data.append(temp)\n",
    "                \n",
    "                elif mag_limitation[0] is not None or mag_limitation[1] is not None:\n",
    "                    if mag_limitation[0] is not None:\n",
    "                        if mag_limitation[0] < Mag[j]:\n",
    "                            temp = []\n",
    "                            for i in range(len(name_list)):\n",
    "                                temp.append(fits_file_data.field(name_list[i])[j])\n",
    "                            data.append(temp)\n",
    "                    \n",
    "                    else:\n",
    "                        if Mag[j] <= mag_limitation[1]:\n",
    "                            temp = []\n",
    "                            for i in range(len(name_list)):\n",
    "                                temp.append(fits_file_data.field(name_list[i])[j])\n",
    "                            data.append(temp)\n",
    "                    \n",
    "                else:\n",
    "                    temp = []\n",
    "                    for i in range(len(name_list)):\n",
    "                        temp.append(fits_file_data.field(name_list[i])[j])\n",
    "                    data.append(temp)\n",
    "        if file_create:\n",
    "            return Gaia_Simplified_File_Create(path, next_folder, mag_limitation, name_list, data)\n",
    "        if return_data:\n",
    "            return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "75b9a809-2ab2-496a-892b-ca74c8c97e3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def Gaia_Simplified_File_Create(path,\n",
    "                                next_folder,\n",
    "                                mag_limitation,\n",
    "                                name_list,\n",
    "                                data): #This function only can work with Gaia_EDR3_Data_Split Function\n",
    "    path = path.replace('gaiaedr3_wd_main.fits.gz' , next_folder)\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "        \n",
    "# 以写方式打开文件。注意添加 newline=\"\"，否则会在两行数据之间都插入一行空白。\n",
    "    with open(path+'/selected_data_{0}_{1}.csv'.format(mag_limitation[0] , mag_limitation[1]), mode=\"w\", encoding=\"utf-8-sig\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(name_list)\n",
    "        writer.writerows(data)\n",
    "    return path +'/selected_data_{0}_{1}.csv'.format(mag_limitation[0] , mag_limitation[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "991f3cc7-5490-456b-b7cc-fbcaeb5674c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Gaia_EDR3_Data_Split(path, name_list, Pwd_limitation, mag_limitation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51097ee-c51b-427e-9c5c-14332c497ef2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "71b051dd-8ce8-4efb-a4be-da7f36b61518",
   "metadata": {},
   "source": [
    "## __Cross-match with LAMOST by Radius Search__ ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83df18e3-8d89-4bab-b012-a34769e1f32b",
   "metadata": {},
   "source": [
    "* __only support a *.csv or *.txt with ra and dec list__  \n",
    " ( the result file is in the same folder as your file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "26d005a5-1fa1-4e1b-bbcf-33d72e2fd15c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# the needed module import\n",
    "import pandas as pd   \n",
    "import os\n",
    "\n",
    "# the needed module import\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.edge.options import Options\n",
    "import time\n",
    "\n",
    "import urllib as url\n",
    "\n",
    "import re\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm,trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "667e7569-7c78-4b85-8b73-8fd3afbd37f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class InputError(Exception):\n",
    "    pass\n",
    "class HTTPError(Exception):\n",
    "    pass\n",
    "def Csv_File_Cross_Match(file_dir,\n",
    "                         sec = 2.0,\n",
    "                         txt_save = False):\n",
    "    if Path(file_dir).parts[len(Path(file_dir).parts)-1][len(Path(file_dir).parts[len(Path(file_dir).parts)-1]) - 4 :] != '.csv':\n",
    "        raise InputError('Wrong file_dir is inputted')\n",
    "        \n",
    "    num = sum(1 for line in open(file_dir))-1\n",
    "    Ra = list(pd.read_csv(file_dir , index_col = ['ra']).T)\n",
    "    Dec = list(pd.read_csv(file_dir , index_col = ['dec']).T)\n",
    "    \n",
    "    temp_txt = file_dir.replace('.csv', '.txt')\n",
    "    work = open(temp_txt , mode='w')\n",
    "    for j in trange(0, num):\n",
    "        work.write(str(Ra[j]) + ',' + str(Dec[j]) + ',' + str(sec) + '\\n')\n",
    "    work.close()\n",
    "    \n",
    "    #displayed or not setting\n",
    "    opt = Options()\n",
    "    opt.add_argument('--headless')\n",
    "    driver = webdriver.Edge(options = opt)\n",
    "    driver.get('http://www.lamost.org/dr8/v2.0/search')\n",
    "    #上传\n",
    "    driver.find_element(By.XPATH,\"//html/body/div[2]/form/div[2]/div[1]/div/table/tbody/tr[4]/td[3]/input\").send_keys(temp_txt)\n",
    "    #选择 proximity 查找\n",
    "    driver.find_element(By.XPATH,\"//html/body/div[2]/form/div[2]/div[1]/div/table/tbody/tr[4]/td[1]/span/input\").click()\n",
    "    #点击 search\n",
    "    driver.find_element(By.XPATH,\"//html/body/div[2]/form/div[2]/div[2]/input[1]\").click()\n",
    "    #HTML进入跳转页面并等待3s，防止页面未显示\n",
    "    driver.switch_to.window(driver.window_handles[-1])\n",
    "    \n",
    "    #获取sqlid，以便导出匹配结果\n",
    "    query = url.parse.urlparse(driver.current_url).query\n",
    "    driver.close()\n",
    "    time.sleep(3)\n",
    "    if not txt_save:\n",
    "        os.remove(temp_txt)\n",
    "\n",
    "    if query == '':\n",
    "        raise HTTPError('the connection to LAMOST is failed')\n",
    "    else:\n",
    "        sqlid = re.findall(\"\\d+\",query)[0]\n",
    "    \n",
    "        #匹配结果下载\n",
    "        response = url.request.urlopen('http://www.lamost.org/dr8/v2.0/sqlidall/{0}?output.fmt=csv&'.format(sqlid))\n",
    "        name = response.getheader(\"Content-disposition\").split('=')[1]\n",
    "        data = response.read()\n",
    "    \n",
    "        savefile = file_dir.replace(Path(file_dir).parts[len(Path(file_dir).parts)-1], name)\n",
    "    \n",
    "        with open(savefile , 'wb+') as fh:\n",
    "            fh.write(data)\n",
    "            fh.close()\n",
    "        \n",
    "        result_file = file_dir.replace('.csv', '_cross_match.csv')\n",
    "        os.rename(savefile , result_file)\n",
    "        return result_file\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d59b40fe-8c7c-4a22-b4bd-b03956712998",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Csv_File_Cross_Match('C:/Users/Administrator/Desktop/大创/Data/Gaia/selected_data_None_None.csv',\n",
    "                         sec = 2.0,\n",
    "                         txt_save = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb10030-1ce7-4bf2-9fcb-ebf45ef37af9",
   "metadata": {},
   "source": [
    "## __Download Spectrum Data by Obsid__ ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b2f8453-ee03-40f0-8f9d-983fe1daa6f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# necessary module\n",
    "import urllib as url\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "import threading\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "from tqdm import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e09db80-ef99-41bf-b64a-0f1b7b1c3011",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Souce_Result_Match(cross_match_file, \n",
    "                       source_file, \n",
    "                       name = 'WDJ_name'):\n",
    "    obsid = list(pd.read_csv(cross_match_file, sep = '|', index_col = ['combined_obsid']).T)\n",
    "    input_id = list(pd.read_csv(cross_match_file, sep = '|', index_col = ['inputobjs_input_id']).T)\n",
    "    source_id = list(pd.read_csv(source_file, index_col = [name]).T)\n",
    "    match_name = []\n",
    "    for i in trange(0, len(input_id)):\n",
    "        match_name.append(source_id[input_id[i]])\n",
    "    return [match_name, obsid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0b9ce98c-ce15-4eec-94d9-a9c41e06d367",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Download_Fits(path,\n",
    "                  obsid):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    if type(obsid) == int:\n",
    "        link = 'http://www.lamost.org:80/dr8/v2.0/spectrum/fits/{0}?token='.format(obsid)\n",
    "        fits.open(link).writeto(path + '/' + fits.open(link)[0].header['FILENAME'], output_verify='ignore')\n",
    "    elif type(obsid) == list:\n",
    "        for i in obsid:\n",
    "            link = 'http://www.lamost.org:80/dr8/v2.0/spectrum/fits/{0}?token='.format(obsid[i])\n",
    "            fits.open(link).writeto(path + '/' + fits.open(link)[0].header['FILENAME'], output_verify='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b0e5dcbc-6d97-4db3-91b2-039b788e6b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cross_Match_Result_Fits_Download(match,\n",
    "                                     path,\n",
    "                                     thread_num = 50,\n",
    "                                     thread_flag = True):\n",
    "    if len(match) != 2:\n",
    "        raise InputError('the match should be a list with 2 lists of souce_id and obsid')\n",
    "    if len(match[0]) != len(match[1]):\n",
    "        raise InputError('the lenth of souce_id is not the same as obsid')\n",
    "    if type(thread_num) != int:\n",
    "        thread_num = int(thread_num)\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    \n",
    "    if not thread_flag:\n",
    "        for i in trange(0, len(match[1])):\n",
    "            Download_Fits(path + '/' + str(match[0][i]) + '/' + str(match[1][i]), int(match[1][i]))\n",
    "    else:\n",
    "        if len(match[0]) <= thread_num:\n",
    "            threads = []\n",
    "            for i in trange(len(match[0])):\n",
    "                t = threading.Thread(target = Download_Fits, args=(path + '/' + str(match[0][i]) + '/' + str(match[1][i]), int(match[1][i])))\n",
    "                threads.append(t)\n",
    "            for t in (threads):\n",
    "                t.start()  # 调用start()方法，开始执行\n",
    "            for t in (threads):\n",
    "                t.join()\n",
    "        else:\n",
    "            if len(match[0]) % thread_num == 0 :\n",
    "                lists_lenth = int(len(match[0]) / thread_num)\n",
    "            else:\n",
    "                lists_lenth = int(len(match[0]) / thread_num) + 1\n",
    "                \n",
    "            source_id = []\n",
    "            obsid = []\n",
    "            for i in range(lists_lenth):\n",
    "                source_id.append(match[0][i * thread_num : (i + 1) * thread_num])\n",
    "                obsid.append(match[1][i * thread_num : (i + 1) * thread_num])\n",
    "                \n",
    "            for j in trange(0, lists_lenth):\n",
    "                threads = []\n",
    "                for i in range(len(source_id[j])):\n",
    "                    t = threading.Thread(target = Download_Fits, args=(path + '/' + str(source_id[j][i]) + '/' + str(obsid[j][i]), int(obsid[1][i])))\n",
    "                    threads.append(t)\n",
    "                for t in (threads):\n",
    "                    t.start()  # 调用start()方法，开始执行\n",
    "                for t in (threads):\n",
    "                    t.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "575a9e7e-87ca-49f5-8b3d-965bdaa93b90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cross_match_file = r'C:\\Users\\Administrator\\Desktop\\大创\\Data\\temp\\selected_data_None_None_cross_match.csv'\n",
    "source_file = r'C:\\Users\\Administrator\\Desktop\\大创\\Data\\temp\\selected_data_None_None.csv'\n",
    "match = Souce_Result_Match(cross_match_file, source_file, name = 'EDJ_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1661fe7f-7f32-4154-b86b-d3e006f94c12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path = r'C:\\Users\\Administrator\\Desktop\\大创\\Data\\Gaia\\test'\n",
    "Cross_Match_Result_Fits_Download(match, path, thread_num = 50, thread_flag = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27528423-9226-43e8-9bbb-121de529cb31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1af4a7dc-3fd1-47d8-b256-feb25f082a7c",
   "metadata": {},
   "source": [
    "## __Spectral Line Determination through Average Method__ ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf40643a-5f1f-4ad5-be35-bb5bbd25e78c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "\n",
    "import numpy as np\n",
    "from astropy.io import fits\n",
    "\n",
    "import scipy.interpolate as spi\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import cv2\n",
    "\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "636fc1f8-c99a-4e3e-87fa-1c485c210174",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def Delta_cal(x,\n",
    "              y,\n",
    "              line,\n",
    "              center_broading,\n",
    "              peripheral_broading\n",
    "             ):\n",
    "    ave_c = sum(y[(line - center_broading < x)&(x < line + center_broading)]) / len(y[(line - center_broading < x)&(x < line + center_broading)])\n",
    "            \n",
    "    ave_p = ((sum(y[(line + center_broading < x)&(x < line + center_broading + peripheral_broading)]) \n",
    "             + sum(y[(line - center_broading - peripheral_broading < x)&(x < line - center_broading)])) \n",
    "             / (len(y[(line + center_broading < x)&(x < line + center_broading + peripheral_broading)]) \n",
    "                + len(y[(line - center_broading - peripheral_broading < x)&(x < line - center_broading)])))\n",
    "    return (ave_p - ave_c) / (max(y) - min(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bfa0448e-551b-4b67-8038-959c1f484f0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def Determination_of_Spectral_Lines(x, \n",
    "                                    y,\n",
    "                                    z,\n",
    "                                    lines,\n",
    "                                    delta,\n",
    "                                    center_broading,\n",
    "                                    peripheral_broading\n",
    "                                   ):\n",
    "    line = []\n",
    "    for i in range(0, len(lines)):\n",
    "        line.append(lines[i] / (z + 1))\n",
    "        #Warning: Lines_included should be hard copied to avoid the change of its data \n",
    "        \n",
    "    flag = 0\n",
    "    n = 0\n",
    "    #print(min(x))\n",
    "    #print(max(x))\n",
    "    \n",
    "    for i in range(0,len(line)):\n",
    "        if min(x) <= line[i] <= max(x):\n",
    "            n = n + 1\n",
    "            if Delta_cal(x, y, line[i], center_broading, peripheral_broading) >= delta:\n",
    "                flag = flag + 1\n",
    "\n",
    "            else:\n",
    "                break\n",
    "    if n != 0 and n == flag:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "57950d0e-5cb3-44cf-bd86-d59e4e642fcd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def is_number(string):\n",
    "    pattern = re.compile(r'^[-+]?[0-9]*\\.?[0-9]+([eE][-+]?[0-9]+)?$')\n",
    "    return bool(pattern.match(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "11e5122a-7157-4d01-8f6c-8fdfe8f80cfa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class InputError(Exception):\n",
    "    pass\n",
    "def File_Spectral_Lines_Check(file,\n",
    "                              lines_included,\n",
    "                              delta = 3.5e-06,\n",
    "                              center_broading = 5,\n",
    "                              peripheral_broading = 15,\n",
    "                              lines_excluded = None,\n",
    "                              sn = 0):\n",
    "    if lines_excluded != None and lines_excluded != list and is_number(str(lines_excluded)):\n",
    "            raise InputError('lines_excluded should be a form among Nonetype, list and number')\n",
    "    if lines_included != list and is_number(str(lines_included)):\n",
    "        raise InputError('lines_included should be a form among list and number')\n",
    "    \n",
    "    file_fits = fits.open(file)\n",
    "    x = file_fits[1].data[0].field('WAVELENGTH')\n",
    "    y = file_fits[1].data[0].field('FLUX')\n",
    "    z = file_fits[0].header['Z']\n",
    "    sng = file_fits[0].header['SNRU']\n",
    "    file_fits.close()\n",
    "    if z == -9999:\n",
    "        z = 0\n",
    "    \n",
    "    ipo = spi.splrep(x , y , k = 3)\n",
    "    X = x\n",
    "    Y = spi.splev(X, ipo)\n",
    "    Y = cv2.GaussianBlur(src = Y, ksize = (29, 29), sigmaX = 5)\n",
    "    \n",
    "    if sng > sn:\n",
    "        if lines_excluded != None:\n",
    "            if type(lines_excluded) != list:\n",
    "                lines_ex = [lines_excluded]\n",
    "            else:\n",
    "                lines_ex = lines_excluded \n",
    "            flag0 = Determination_of_Spectral_Lines(x, y, z, lines_ex, delta, center_broading, peripheral_broading)\n",
    "            flag1 = Determination_of_Spectral_Lines(X, Y, z, lines_ex, delta, center_broading, peripheral_broading)\n",
    "            if flag0 and flag1:\n",
    "                return False\n",
    "            elif flag0 or flag1:\n",
    "                return 'Please inspect visually'\n",
    "                \n",
    "        if type(lines_included) != list:\n",
    "            lines_in = [lines_included]\n",
    "        else:\n",
    "            lines_in = lines_included\n",
    "        flag0 = Determination_of_Spectral_Lines(x, y, z, lines_in, delta, center_broading, peripheral_broading)\n",
    "        flag1 = Determination_of_Spectral_Lines(X, Y, z, lines_in, delta, center_broading, peripheral_broading)\n",
    "        if flag0 and flag1:\n",
    "            text = str(file_fits[0].header['OBSID']) + '/' + file_fits[0].header['FILENAME']\n",
    "            return text\n",
    "        elif flag0 or flag1:\n",
    "            return 'Please inspect visually'\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "25b3d9fa-6c60-4767-a5aa-da066438b47c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def Multiply_Files_Spectral_Lines_Check(path_dir, \n",
    "                                        lines_included,\n",
    "                                        delta = 3.5e-06,\n",
    "                                        center_broading = 5,\n",
    "                                        peripheral_broading = 15,\n",
    "                                        lines_excluded = None,\n",
    "                                        sn = 0):\n",
    "    visual_inspect = []\n",
    "    name = []\n",
    "    path = []\n",
    "    if os.path.isfile(path_dir):\n",
    "        path.append(path_dir)\n",
    "    else:\n",
    "        for root,dirs,files in os.walk(path_dir):\n",
    "            for file in files:\n",
    "                temp = os.path.join(root,file)\n",
    "                path.append(temp)\n",
    "    for i in trange(0,len(path)):\n",
    "        p = File_Spectral_Lines_Check(path[i], lines_included, delta = delta, center_broading = center_broading, peripheral_broading = peripheral_broading, lines_excluded = lines_excluded, sn = sn)\n",
    "        if p == 'Please inspect visually':\n",
    "            visual_inspect.append(path[i])\n",
    "        elif p:\n",
    "            name.append(p)\n",
    "    return [name, visual_inspect]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "28b45b8c-e9cb-4f1c-926f-8788d821aa6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DA = {\n",
    "    3970:r'H$\\epsilon$',\n",
    "    3891:r'H$\\zeta$',\n",
    "    4101.7:r'H$\\delta$',\n",
    "    4340.4:r'H$\\gamma$',\n",
    "    4861.3:r'H$\\beta$',\n",
    "    6562.7:r'H$\\alpha$'}\n",
    "DB = {\n",
    "    4471 : 'He I'\n",
    "};\n",
    "DZ = {\n",
    "    3933.7:'Ca II K',\n",
    "    3968.5:'Ca II H',\n",
    "};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c4d6aa6c-4e50-43f1-be2e-ff94408c37d9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9270/9270 [14:42<00:00, 10.51it/s]\n"
     ]
    }
   ],
   "source": [
    "a = Multiply_Files_Spectral_Lines_Check(r'C:\\Users\\Administrator\\Desktop\\大创\\Data\\temp\\test', list(DA.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a3c0c885-3eab-41a7-949e-28ac975e17fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4976"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(a[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2e4660-a82e-436b-ba01-2b5a14d3cef1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
